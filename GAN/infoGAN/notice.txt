1. 这种loss是只训练2个network，将q的loss同时加到D和G的loss中，
	然后分别对D和G优化
2.也是训练3个网络，本来就分了3个网络出来。原始的D和G，
	以及新增的Q。 Q网络的输入时D中hidden引出来的输出。
	q_loss对3个网络的参数求梯度
3. 该种形式是训练3个network，原始的D和G，新增的Q，Q网络的参数是D+G+Q
	Q的输入时D网络中倒数第二层(最后一层输出实数)的输出。
	q_loss对3个网络的参数求梯度

	虽然D中最后一层的参数与Q无关，对D所有的参数优化也不影响。
